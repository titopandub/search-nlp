{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "vectorized_file = open(\"data/vectorized.json\")\n",
    "vectorized = json.load(vectorized_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "vocab_file = open(\"data/vocab.json\")\n",
    "vocab = json.load(vocab_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def build_corpus_vocabulary(documents_with_tf_idfs, vocabulary):\n",
    "  inverted_index = dict()\n",
    "\n",
    "  for index, token in enumerate(sorted(vocabulary.keys())):\n",
    "    inverted_index[token] = []\n",
    "    for document in documents_with_tf_idfs:\n",
    "      tf_idf = document[\"tf_idfs\"][index]\n",
    "      if tf_idf > 0:\n",
    "        inverted_index[token].append((document[\"title\"], tf_idf))\n",
    "\n",
    "  return inverted_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Pandemic', 0.3611111111111111),\n ('Spanish flu', 2.1666666666666665),\n ('Swine influenza', 3.611111111111111),\n ('Unified Victim Identification System', 0.3611111111111111)]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index = build_corpus_vocabulary(vectorized, vocab)\n",
    "\n",
    "inverted_index[\"flu\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def tokenizer(string):\n",
    "    lowercased = string.lower()\n",
    "    lowercased = re.sub('(\\n|\\\\\\\\displaystyle)', '', lowercased)\n",
    "    doc = nlp(lowercased)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space:\n",
    "            lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "def search_inverted_index(query, inverted_index_dict):\n",
    "  query_token = tokenizer(query)\n",
    "  results = []\n",
    "  for token in query_token:\n",
    "    results.append(inverted_index_dict[token])\n",
    "\n",
    "  results = list(chain(*results))\n",
    "  calculated_results = defaultdict(int)\n",
    "  for document, score in results:\n",
    "      calculated_results[document] += score\n",
    "\n",
    "  calculated_results = [(key, value) for key, value in calculated_results.items()]\n",
    "  calculated_results = sorted(calculated_results, key=lambda x: x[1], reverse=True)\n",
    "  return calculated_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Spanish flu', 7.944444444444443),\n ('Swine influenza', 5.055555555555555),\n ('Pandemic', 1.8055555555555554),\n ('Unified Victim Identification System', 0.3611111111111111)]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_inverted_index(\"Spanish flu\", inverted_index, )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "with open(\"data/data_vectorized.json\", \"w\") as file:\n",
    "  json.dump(inverted_index, file, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}